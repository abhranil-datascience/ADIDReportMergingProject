{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "precious-invention",
   "metadata": {},
   "source": [
    "# Make editor section wider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "designed-grain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import display_javascript, display_html, display\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-mortgage",
   "metadata": {},
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "internal-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import traceback\n",
    "import string,random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-maker",
   "metadata": {},
   "source": [
    "# Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "refined-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "shouldProceed=True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-history",
   "metadata": {},
   "source": [
    "# Read Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "therapeutic-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "if shouldProceed:\n",
    "    try:\n",
    "        ConstantsFile = '/home/ubuntu/Abhranil/Projects/Python/UnniProject/Constants.xlsx'\n",
    "        if not(os.path.exists(ConstantsFile)):\n",
    "            print(\"Stopping Execution as Constants File does not exists !!\")\n",
    "            shouldProceed = False\n",
    "        else:\n",
    "            ConstantsDF = pd.read_excel(ConstantsFile)\n",
    "            TypeAFilePath = list(ConstantsDF[ConstantsDF['key']==\"TypeAFilePath\"]['value'])[0]\n",
    "            TypeBFilePath = list(ConstantsDF[ConstantsDF['key']==\"TypeBFilePath\"]['value'])[0]\n",
    "            if not(os.path.exists(TypeAFilePath)):\n",
    "                print(\"Stopping Execution as Type A File does not exists !!\")\n",
    "                shouldProceed = False\n",
    "            elif not(os.path.exists(TypeBFilePath)):\n",
    "                print(\"Stopping Execution as Type B File does not exists !!\")\n",
    "                shouldProceed = False\n",
    "            TypeAPrimaryKeyIndex = int(list(ConstantsDF[ConstantsDF['key']==\"TypeAPrimaryKeyIndex\"]['value'])[0])-1\n",
    "            TypeBForeignKeyIndex = int(list(ConstantsDF[ConstantsDF['key']==\"TypeBForeignKeyIndex\"]['value'])[0])-1\n",
    "            OutputDirectoryPath = list(ConstantsDF[ConstantsDF['key']==\"OutputDirectoryPath\"]['value'])[0]\n",
    "    except Exception as e:\n",
    "        print(\"Error occured while reading input parameters !!\")\n",
    "        print(\"Error Details: \")\n",
    "        print(\"\")\n",
    "        print(\"=====================================================================================================================================================\")\n",
    "        print(\"\")\n",
    "        print(traceback.format_exc())\n",
    "        print(\"\")\n",
    "        print(\"=====================================================================================================================================================\")\n",
    "        shouldProceed = False\n",
    "else:\n",
    "    print(\"Previous Cell stopped execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-accounting",
   "metadata": {},
   "source": [
    "# Read Type A and Type B files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "consecutive-operation",
   "metadata": {},
   "outputs": [],
   "source": [
    "if shouldProceed:\n",
    "    try:\n",
    "        TypeA_DF = pd.read_csv(TypeAFilePath)\n",
    "        with open(TypeBFilePath) as b:\n",
    "            linesList = b.readlines()\n",
    "        max_len= 0 \n",
    "        for line in linesList:\n",
    "            thrd_part_len = len(line.split(\"\\t\")[2].replace(\"\\n\",\"\").split(\",\"))\n",
    "            if thrd_part_len > max_len:\n",
    "                max_len = thrd_part_len\n",
    "        TypeBColumnNames=['Column1','Column2',\"Traits\"]\n",
    "        Column1List = []\n",
    "        Column2List = []\n",
    "        Column3List = []\n",
    "        for pos,line in enumerate(linesList):\n",
    "            current_row=[]\n",
    "            current_line_splitted = line.split('\\t')\n",
    "            Column1List.append(current_line_splitted[0].strip())\n",
    "            Column2List.append(current_line_splitted[1].strip())\n",
    "            Column3List.append(current_line_splitted[2].replace(\"\\n\",\"\").strip())\n",
    "        TypeB_Dict = dict(Column1 = Column1List,Column2 = Column2List,Traits = Column3List)\n",
    "        TypeB_DF = pd.DataFrame.from_dict(TypeB_Dict)\n",
    "    except Exception as e:\n",
    "        print(\"Error occured while reading Type A and Type B files !!\")\n",
    "        print(\"Error Details: \")\n",
    "        print(\"\")\n",
    "        print(\"=====================================================================================================================================================\")\n",
    "        print(\"\")\n",
    "        print(traceback.format_exc())\n",
    "        print(\"\")\n",
    "        print(\"=====================================================================================================================================================\")\n",
    "        shouldProceed = False\n",
    "else:\n",
    "    print(\"Previous Cell stopped execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-forge",
   "metadata": {},
   "source": [
    "# Clean Matching Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "separate-transsexual",
   "metadata": {},
   "outputs": [],
   "source": [
    "if shouldProceed:\n",
    "    try:\n",
    "        TypeAPrimaryKeyIndex\n",
    "        TypeAColumnName = TypeA_DF.columns[TypeAPrimaryKeyIndex]\n",
    "        TypeBColumnName = TypeB_DF.columns[TypeBForeignKeyIndex]\n",
    "        TypeAColumnCleaned = []\n",
    "        TypeAColumnValues = TypeA_DF[TypeAColumnName]\n",
    "        for item in TypeAColumnValues:\n",
    "            TypeAColumnCleaned.append(item.lower().strip())\n",
    "        TypeA_DF[TypeAColumnName] = TypeAColumnCleaned\n",
    "        TypeBColumnCleaned = []\n",
    "        TypeBColumnValues = TypeB_DF[TypeBColumnName]\n",
    "        for item in TypeBColumnValues:\n",
    "            TypeBColumnCleaned.append(item.lower().strip())\n",
    "        TypeB_DF[TypeBColumnName] = TypeBColumnCleaned\n",
    "    except Exception as e:\n",
    "        print(\"Error occured while cleaning A type and B type files !!\")\n",
    "        print(\"Error Details: \")\n",
    "        print(\"\")\n",
    "        print(\"=====================================================================================================================================================\")\n",
    "        print(\"\")\n",
    "        print(traceback.format_exc())\n",
    "        print(\"\")\n",
    "        print(\"=====================================================================================================================================================\")\n",
    "        shouldProceed = False\n",
    "else:\n",
    "    print(\"Previous Cell stopped execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-trunk",
   "metadata": {},
   "source": [
    "# Merge Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "laden-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "if shouldProceed:\n",
    "    try:\n",
    "        TypeA_DF_uniques = TypeA_DF.drop_duplicates()\n",
    "        TypeB_DF_uniques = TypeB_DF.drop_duplicates()\n",
    "        Merged_DF = pd.merge(TypeA_DF_uniques,TypeB_DF_uniques,left_on=[TypeAColumnName],right_on=[TypeBColumnName])\n",
    "    except Exception as e:\n",
    "        print(\"Error occured while merging A and B type files !!\")\n",
    "        print(\"Error Details: \")\n",
    "        print(\"\")\n",
    "        print(\"=====================================================================================================================================================\")\n",
    "        print(\"\")\n",
    "        print(traceback.format_exc())\n",
    "        print(\"\")\n",
    "        print(\"=====================================================================================================================================================\")\n",
    "        shouldProceed = False\n",
    "else:\n",
    "    print(\"Previous Cell stopped execution\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-layout",
   "metadata": {},
   "source": [
    "# Beautify Merged Dataframe and write to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "universal-category",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Report MergedReport_ZSD3YLQ.csv written successfully !!\n"
     ]
    }
   ],
   "source": [
    "if shouldProceed:\n",
    "    try:\n",
    "        Merged_DF = Merged_DF[['Column2','member_id','ADID','Traits']]\n",
    "        Merged_DF.columns=[\"MID\",\"MemberID\",\"ADID\",\"Traits\"]\n",
    "        Merged_DF = Merged_DF.sort_values(by=\"MID\")\n",
    "        Merged_DF = Merged_DF.reset_index(drop=True)\n",
    "        Merged_DF_random_part = ''.join(random.choices(string.ascii_uppercase+string.digits,k=7))\n",
    "        OutputFileName = \"MergedReport_\"+Merged_DF_random_part+\".csv\"\n",
    "        OuputFilePath = OutputDirectoryPath+OutputFileName\n",
    "        Merged_DF.to_csv(path_or_buf=OuputFilePath,sep=\"\\t\",index=False)\n",
    "        print(\"Merged Report\",OutputFileName,\"written successfully !!\")\n",
    "    except Exception as e:\n",
    "        print(\"Error occured while writing merged report to disk !!\")\n",
    "        print(\"Error Details: \")\n",
    "        print(\"\")\n",
    "        print(\"=====================================================================================================================================================\")\n",
    "        print(\"\")\n",
    "        print(traceback.format_exc())\n",
    "        print(\"\")\n",
    "        print(\"=====================================================================================================================================================\")\n",
    "        shouldProceed = False\n",
    "else:\n",
    "    print(\"Previous Cell stopped execution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-hazard",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
